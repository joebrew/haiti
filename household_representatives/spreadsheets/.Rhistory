?ksline
q <- ksline(b, cov.model="exp",cov.pars=c(10,3.33), nugget=0,
head(in_mat)
q <- ksline(b, cov.model="exp",cov.pars=c(10,3.33), nugget=0,
locations=in_mat)
plot(q)
q
q$predict
image(q, val=q$predict)
image(as.matrix(q), val=q$predict)
as.matrix(q
)
q[,"sp.dim"]
q$prediction.locations
names(q)
q$locations
plot(q$locations)
image(q$locations)
image(q$locations, val=q$predict)
image(q$locations, val=q$predict)
warnings()
image(q$locations, as.matrix(q$predict))
q$locations
source('~/.active-rstudio-document', echo=TRUE)
heatmap(q)
heatmap(as.matrix(q))
as.matrix(q)
heatmap(as.matrix(q$locations))
?heatmap
?filled.contour
head(in_mat)
head(b)
b
a
filled.contour(a)
filled.contour(x= a$x,
y = a$y,
z = a$z)
a <- a[order(c(a$x, a$y)),]
a
a <- data.frame("x" = loc$lon,
"y" = loc$lat,
"z" = temp)
a <- a[with(aa, order(a$x, a$y)),]
a <- a[with(a, order(a$x, a$y)),]
filled.contour(x= a$x,
y = a$y,
z = a$z)
library(gstat)
library(geoR)
disease <- "wnv"
temp <- master[,which(grepl(disease ,colnames(master)) &
grepl("site", colnames(master)))]
load("C:/Users/BrewJR/Documents/fdoh/public/mosquito/reports/2014-10-14/master.RData")
disease <- "wnv"
temp <- master[,which(grepl(disease ,colnames(master)) &
grepl("site", colnames(master)))]
temp <- as.data.frame(cbind(date=master$date, temp))
temp <- temp[which(temp$date ==
max(temp$date[which(is.na(temp[,paste0(disease, "site1")]) == FALSE)])),]
temp <- as.numeric(temp[-1])
a <- data.frame("x" = loc$lon,
"y" = loc$lat,
"z" = temp)
b <- as.geodata(a)
prediction <- ksline(b, cov.model="exp", cov.pars=c(10,3.33), nugget=0,
locations=c(-82.15,29.323))
# Predict multiple points
x <- seq(-83, -82, by=0.01)
y <- seq(29,30, by=0.01)
xv <- rep(x,14)
yv <- rep(y, each=14)
head(in_mat)
in_mat
in_mat <- as.matrix(cbind(xv,yv))
head(in_mat)
heatmap(as.matrix(q$locations))
q <- ksline(b, cov.model="exp",cov.pars=c(10,3.33), nugget=0,
locations=in_mat)
filled.contour(in_mat, q$predict)
q$locations
x <- data.frame("x" = q$locations[,1],
"y" = q$locations[,2],
"predict" = q$predict)
filled.contour(list(x))
head(x)
image(x)
image(x)
xg <- as.geodata(x)
plot(xg)
image(xg)
image(xg, z= matrix(x$predit))
image(xg, z= matrix(x$predict))
?image
xg
head(x)
image(x = x, zcol = "z",
xcol = "x")
image(x = x$x,
y = x$y,
z = x$predict)
x <- x[order(x$x),]
head(x)
x <- x[rev(order(x$x)),]
head(x)
x <- x[with(x, order(x,y)),]
head(x)
x <- x[with(x, rev(order(x,y))),]
head(x)
image(x = seq(-83, -82, by=0.01),
y =  seq(29,30, by=0.01),
z = x$predict)
x$predict
q$predict
image(x = seq(-83, -82, by=0.01),
y =  seq(29,30, by=0.01),
z = matrix(x$predict))
image(x = seq(-83, -82, by=0.01),
y =  seq(29,30, by=0.01),
z = matrix(x$predict, ncol = length(seq(29,30, by=0.01)))
image(x = seq(-83, -82, by=0.01),
y =  seq(29,30, by=0.01),
z = matrix(x$predict, ncol = length(seq(29,30, by=0.01)))
)
levelplot(predict ~ x*y, data = x,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "Surface elevation data",
col.regions = terrain.colors(100)
)
library(lattice)
levelplot(predict ~ x*y, data = x,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "Surface elevation data",
col.regions = terrain.colors(100)
)
levelplot(predict ~ x*y, data = x,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "Surface elevation data",
col.regions = terrain.colors(500)
)
levelplot(predict ~ x*y, data = q,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "Surface elevation data",
col.regions = terrain.colors(500)
)
names(q)
q$predict
q$locations
levelplot(predict ~ locations, data = q,
xlab = "X Coordinate (feet)", ylab = "Y Coordinate (feet)",
main = "Surface elevation data",
col.regions = terrain.colors(500)
)
kc4 <- krige.conv(b, locations = in_mat,
krige = krige.control(obj.m=wls))
?krige.control
kc4 <- krige.conv(b, locations = in_mat,
krige = krige.control(obj.m=OK))
kc4 <- krige.conv(b, locations = in_mat,
krige = krige.control(type.krige = "ok"))
b$coords
b$data
kc4 <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = in_mat,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok"))
?krige.control
kc4 <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = in_mat,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
mykrig <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = in_mat,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
plot(mykrig)
image(mykrig)
mykrig$x
mykrig$predict
mykrig
mykrig$locations
names(mykrig)
summary(mykrig)
x
plot(b$coords)
plot(in_mat)
grd(in_mat)
library(scatterplot3d)
install.packages("scatterplot3d")
install.packages("scatterplot3d")
scatterplot3d(in_mat)
library(scatterplot3d)
scatterplot3d(in_mat)
summary(mykrig)
scatterplot3d(in_mat, mykrig$predict)
scatterplot3d(in_mat[,1], in_mat[,2], mykrig$predict)
scatterplot3d(in_mat[,1], in_mat[,2], mykrig$predict,
pch = 16, col = adjustcolor("black", alpha.f = 0.2))
scatterplot3d(in_mat[,1], in_mat[,2], mykrig$predict)
image(in_mat[,1], in_mat[,2], mykrig$predict)
head(inmat)
head(in_mat)
x <- seq(-83, -82, by=0.01)
y <- seq(29,30, by=0.01)
xv <- rep(x,each=14)
yv <- rep(y, 14)
in_mat <- as.matrix(cbind(xv,yv))
#   in_mat <- data.frame(in_mat)
#   names(in_mat) <- c("x", "y")
#   in_mat <- as.geodata(in_mat)
#
# Predict using kriging (another method)
mykrig <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = in_mat,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
library(scatterplot3d)
scatterplot3d(in_mat[,1], in_mat[,2], mykrig$predict)
plot(in_mat[,1], in_mat[,2])
?grid
grid()
grid()
grid()
grid()
grid()
pred.grid <-  expand.grid(seq(-83,-82, l=51), seq(29,30, l=51))
kc <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = pred.grid,
# borders = ALACHUA BORDERS!,
krige = krige.control(obj.m = ml))
kc <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = pred.grid,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
image(kc, loc = pred.grid, col=gray(seq(1,0.1,l=30)), xlab="Coord X", ylab="Coord Y")
map("county", "fl", add = T)
mymap$polygons
mymap <- map("county","fl")
mymap$polygons
summary(mymap)
mymap$x[which(mymap$names == mymap$names[1])]
image(kc, loc = pred.grid, main = "predicted", col=gray(seq(1,0.1,l=30)))
image(kc, val ="variance", loc = pred.grid,
main = "prediction variance", col=gray(seq(1,0.1,l=30)))
image(kc, val = "simulation", number.col = 1, loc = pred.grid,
main = "a simulation from\nthe predictive distribution", col=gray(seq(1,0.1,l=30)))
image(kc, val = "simulation", number.col = 2,loc = pred.grid,
main = "another simulation from \n the predictive distribution", col=gray(seq(1,0.1,l=30)))
library(gstat)
library(geoR)
load("C:/Users/BrewJR/Documents/fdoh/public/mosquito/reports/2014-10-14/master.RData")
disease <- "wnv"
temp <- master[,which(grepl(disease ,colnames(master)) &
grepl("site", colnames(master)))]
temp <- as.data.frame(cbind(date=master$date, temp))
temp <- temp[which(temp$date ==
max(temp$date[which(is.na(temp[,paste0(disease, "site1")]) == FALSE)])),]
temp <- as.numeric(temp[-1])
a <- data.frame("x" = loc$lon,
"y" = loc$lat,
"z" = temp)
b <- as.geodata(a)
range(b)
names(b)
b$coords
b$coords$x
b$coords["x"]
x <- seq(-83, -82, by=0.01)
y <- seq(29,30, by=0.01)
xv <- rep(x,each=14)
yv <- rep(y, 14)
in_mat <- as.matrix(cbind(xv,yv))
mykrig <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = in_mat,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
library(scatterplot3d)
scatterplot3d(in_mat[,1], in_mat[,2], mykrig$predict)
# defining the grid
pred.grid <-  expand.grid(seq(-83,-82, l=100), seq(29,30, l=100))
# kriging calculations
kc <- krige.conv(geodata = b, coords = b$coords, data = b$data,
locations = pred.grid,
# borders = ALACHUA BORDERS!,
krige = krige.control(type.krige = "ok",
cov.pars = c(10, 3.33)))
# displaying predicted values
image(kc, loc = pred.grid,
col = c("darkblue", "blue", "lightblue", "white", "pink", "red", "darkred"),
#col=gray(seq(1,0.1,l=100)),
xlab="Coord X", ylab="Coord Y")
library(maps)
map("county", "fl", add = T)
points(a$x, a$y)
image(kc, loc = pred.grid,
#col = c("darkblue", "blue", "lightblue", "white", "pink", "red", "darkred"),
col=gray(seq(1,0.1,l=100)),
xlab="Coord X", ylab="Coord Y")
library(maps)
map("county", "fl", add = T)
# Function to generate one random number between 1 and household size (input)
RandomFun <- function(hh_size = 7){
myvec <- vector(length = hh_size, mode = "numeric")
for (i in 1:7){
possibs <- 1:i
myvec[i] <-
sample(x = possibs,
size = 1,
replace = FALSE)
}
return(myvec)
}
# Create dataframe
mydf <- data.frame("hh_number" = 1:3000)
# Generate columns for each possible household size
for (i in 1:7){
mydf[,paste0("hh_size_", i)] <- NA
}
# Populate dataframe with random sequence for each house
for (i in 1:nrow(mydf)){
mydf[i,2:8] <- RandomFun()
}
# Validate to make sure we got a good draw
# (ie, no draws larger than household size, and equal distributions)
# First, define function for calculating confidence interval on proportion:
simpasym <- function(n, p, z=1.96, cc=TRUE){
out <- list()
if(cc){
out$lb <- p - z*sqrt((p*(1-p))/n) - 0.5/n
out$ub <- p + z*sqrt((p*(1-p))/n) + 0.5/n
} else {
out$lb <- p - z*sqrt((p*(1-p))/n)
out$ub <- p + z*sqrt((p*(1-p))/n)
}
out
}
# Now calculate confidence interval on each proportion, and visualize
library(Hmisc)
par(mfrow = c(3,3))
par(mar = c(4,4,2,1))
par(oma = c(0,0,0,0))
for (i in 1:7){
mytable <- table(mydf[,paste0("hh_size_", i)])
ptable <- prop.table(mytable)
mycis <- simpasym(n = 3000,
p = ptable,
z = 1.96,
cc = TRUE)
bp <- barplot(table(mydf[,paste0("hh_size_",i)])  / 3000,
main = paste0("Household size = ", i),
xlab = "HH member selected",
ylab = "Likelihood of being selected",
ylim = c(0, max(mycis$ub)),
cex.lab = 0.6)
errbar(x = bp[,1],
y = ptable,
yplus = mycis$ub,
yminus = mycis$lb,
add = TRUE,
pch = NA,
errbar.col = adjustcolor("darkred", alpha.f = 0.5)
)
}
par(mfrow = c(1,1))
# Write to spreadsheet
setwd("C:/Users/BrewJR/Documents/haiti/random_number_generator")
row.names(mydf) <- NULL
write.csv(mydf, "spreadsheet_for_krishna.csv", row.names = FALSE)
# Function to generate individual table
TableFun <- function(hh_number){
x <- mydf[hh_number,]
names(x) <- c("Household number",
paste0("Household size: ",
1: 7))
row.names(x) <- "Person to be interviewed"
return(x)
}
# Function to write individual table to a spreadsheet
WriteTable <- function(hh_number, out_file = NULL){
x <- mydf[hh_number,]
names(x) <- c("Household number",
paste0("Household size: ",
1: 7))
row.names(x) <- "Person to be interviewed"
if(is.null(out_file)){
write.csv(x, paste0("hh_number_", hh_number, ".csv"), row.names = FALSE)
} else {
write.csv(x, out_file, row.names = FALSE)
}
}
WriteTable(hh_number = 123)
getwd()
setwd("C:/Users/BrewJR/Documents/haiti/random_number_generator")
# Function to generate one random number between 1 and household size (input)
RandomFun <- function(hh_size = 7){
myvec <- vector(length = hh_size, mode = "numeric")
for (i in 1:7){
possibs <- 1:i
myvec[i] <-
sample(x = possibs,
size = 1,
replace = FALSE)
}
return(myvec)
}
# Create dataframe
mydf <- data.frame("hh_number" = 1:3000)
# Generate columns for each possible household size
for (i in 1:7){
mydf[,paste0("hh_size_", i)] <- NA
}
# Populate dataframe with random sequence for each house
for (i in 1:nrow(mydf)){
mydf[i,2:8] <- RandomFun()
}
# Validate to make sure we got a good draw
# (ie, no draws larger than household size, and equal distributions)
# First, define function for calculating confidence interval on proportion:
simpasym <- function(n, p, z=1.96, cc=TRUE){
out <- list()
if(cc){
out$lb <- p - z*sqrt((p*(1-p))/n) - 0.5/n
out$ub <- p + z*sqrt((p*(1-p))/n) + 0.5/n
} else {
out$lb <- p - z*sqrt((p*(1-p))/n)
out$ub <- p + z*sqrt((p*(1-p))/n)
}
out
}
# Now calculate confidence interval on each proportion, and visualize
library(Hmisc)
par(mfrow = c(3,3))
par(mar = c(4,4,2,1))
par(oma = c(0,0,0,0))
for (i in 1:7){
mytable <- table(mydf[,paste0("hh_size_", i)])
ptable <- prop.table(mytable)
mycis <- simpasym(n = 3000,
p = ptable,
z = 1.96,
cc = TRUE)
bp <- barplot(table(mydf[,paste0("hh_size_",i)])  / 3000,
main = paste0("Household size = ", i),
xlab = "HH member selected",
ylab = "Likelihood of being selected",
ylim = c(0, max(mycis$ub)),
cex.lab = 0.6)
errbar(x = bp[,1],
y = ptable,
yplus = mycis$ub,
yminus = mycis$lb,
add = TRUE,
pch = NA,
errbar.col = adjustcolor("darkred", alpha.f = 0.5)
)
}
par(mfrow = c(1,1))
# Write to spreadsheet
setwd("C:/Users/BrewJR/Documents/haiti/household_representatives")
row.names(mydf) <- NULL
write.csv(mydf, "spreadsheet_for_krishna.csv", row.names = FALSE)
# Function to generate individual table
TableFun <- function(hh_number){
x <- mydf[hh_number,]
names(x) <- c("Household number",
paste0("Household size: ",
1: 7))
row.names(x) <- "Person to be interviewed"
return(x)
}
# Function to write individual table to a spreadsheet
WriteTable <- function(hh_number, out_file = NULL){
x <- mydf[hh_number,]
names(x) <- c("Household number",
paste0("Household size: ",
1: 7))
row.names(x) <- "Person to be interviewed"
if(is.null(out_file)){
write.csv(x, paste0("hh_number_", hh_number, ".csv"), row.names = FALSE)
} else {
write.csv(x, out_file, row.names = FALSE)
}
}
# Example of how to write an individual table to a csv
WriteTable(hh_number = 123)
WriteTable(hh_number = 113)
WriteTable(hh_number = 508)
WriteTable <- function(hh_number, out_file = NULL){
x <- mydf[hh_number,]
names(x) <- c("Household number",
paste0("Household size: ",
1: 7))
row.names(x) <- "Person to be interviewed"
if(is.null(out_file)){
write.csv(x, paste0("hh_number_", hh_number, ".csv"))
} else {
write.csv(x, out_file)
}
}
WriteTable(hh_number = 123)
WriteTable(hh_number = 113)
WriteTable(hh_number = 508)
# If you want an individual csv for EVERY household, run the following
setwd("spreadsheets")
for (i in 1:3000){
WriteTable(hh_number = i)
}
